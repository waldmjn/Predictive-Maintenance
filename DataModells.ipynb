{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, RobustScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.ensemble import BalancedBaggingClassifier, BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate, StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from imblearn.under_sampling import TomekLinks, NearMiss, ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, BorderlineSMOTE\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "filepath = \"C:/Users/WALDMJN/OneDrive - Schaeffler/Uni/Data Exploration Project/Pred Maintenance Project/Predictive-Maintenance/Data/predictive_maintenance.csv\"\n",
    "df = pd.read_csv(filepath)\n",
    "df = df.drop([\"UDI\", \"Product ID\"], axis = 1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop out the target anomalies from notebook before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_df = df[df['Target'] == 1]\n",
    "indexPossibleFailure = fail_df[fail_df['Failure Type'] == 'No Failure'].index\n",
    "df.drop(indexPossibleFailure, axis=0, inplace=True)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail_df  = df[df['Target'] == 0]\n",
    "indexPossibleFailure = fail_df[fail_df['Failure Type'] == 'Random Failures'].index\n",
    "df.drop(indexPossibleFailure, axis=0, inplace=True)\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Power [W]'] = df['Torque [Nm]'] * (2 * np.pi * df['Rotational speed [rpm]'] / 60.0)\n",
    "df['Overstrain [minNm]'] = df['Torque [Nm]'] * df['Tool wear [min]']\n",
    "df['Heat dissipation [rpminK]'] = abs(df['Air temperature [K]'] - df['Process temperature [K]']) * df['Rotational speed [rpm]']\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "df[['Type', 'Failure Type']] = encoder.fit_transform(df[['Type', 'Failure Type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Type', 'Air temperature [K]', 'Process temperature [K]',\n",
      "       'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]', 'Target',\n",
      "       'Failure Type', 'Power [W]', 'Overstrain [minNm]',\n",
      "       'Heat dissipation [rpminK]'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RobustScaler on Rotational Speed and Torque is necessary because of strong outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Target</th>\n",
       "      <th>Failure Type</th>\n",
       "      <th>Power [W]</th>\n",
       "      <th>Overstrain [minNm]</th>\n",
       "      <th>Heat dissipation [rpminK]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Power [W]</th>\n",
       "      <th>Overstrain [minNm]</th>\n",
       "      <th>Heat dissipation [rpminK]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551.0</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6951.590560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16285.5</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.474003</td>\n",
       "      <td>-0.929070</td>\n",
       "      <td>0.381501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6826.722724</td>\n",
       "      <td>138.9</td>\n",
       "      <td>14784.0</td>\n",
       "      <td>-0.502646</td>\n",
       "      <td>0.459259</td>\n",
       "      <td>0.387271</td>\n",
       "      <td>-0.896863</td>\n",
       "      <td>-0.122967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7749.387543</td>\n",
       "      <td>247.0</td>\n",
       "      <td>15579.2</td>\n",
       "      <td>-0.026455</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>1.028150</td>\n",
       "      <td>-0.871797</td>\n",
       "      <td>0.144201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5927.504659</td>\n",
       "      <td>276.5</td>\n",
       "      <td>14903.2</td>\n",
       "      <td>-0.370370</td>\n",
       "      <td>-0.044444</td>\n",
       "      <td>-0.237322</td>\n",
       "      <td>-0.864957</td>\n",
       "      <td>-0.082919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5897.816608</td>\n",
       "      <td>360.0</td>\n",
       "      <td>14784.0</td>\n",
       "      <td>-0.502646</td>\n",
       "      <td>-0.007407</td>\n",
       "      <td>-0.257943</td>\n",
       "      <td>-0.845596</td>\n",
       "      <td>-0.122967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  Air temperature [K]  Process temperature [K]  Rotational speed [rpm]  \\\n",
       "0   2.0                298.1                    308.6                  1551.0   \n",
       "1   1.0                298.2                    308.7                  1408.0   \n",
       "2   1.0                298.1                    308.5                  1498.0   \n",
       "3   1.0                298.2                    308.6                  1433.0   \n",
       "4   1.0                298.2                    308.7                  1408.0   \n",
       "\n",
       "   Torque [Nm]  Tool wear [min]  Target  Failure Type    Power [W]  \\\n",
       "0         42.8              0.0     0.0           1.0  6951.590560   \n",
       "1         46.3              3.0     0.0           1.0  6826.722724   \n",
       "2         49.4              5.0     0.0           1.0  7749.387543   \n",
       "3         39.5              7.0     0.0           1.0  5927.504659   \n",
       "4         40.0              9.0     0.0           1.0  5897.816608   \n",
       "\n",
       "   Overstrain [minNm]  Heat dissipation [rpminK]  Rotational speed [rpm]  \\\n",
       "0                 0.0                    16285.5                0.253968   \n",
       "1               138.9                    14784.0               -0.502646   \n",
       "2               247.0                    15579.2               -0.026455   \n",
       "3               276.5                    14903.2               -0.370370   \n",
       "4               360.0                    14784.0               -0.502646   \n",
       "\n",
       "   Torque [Nm]  Power [W]  Overstrain [minNm]  Heat dissipation [rpminK]  \n",
       "0     0.200000   0.474003           -0.929070                   0.381501  \n",
       "1     0.459259   0.387271           -0.896863                  -0.122967  \n",
       "2     0.688889   1.028150           -0.871797                   0.144201  \n",
       "3    -0.044444  -0.237322           -0.864957                  -0.082919  \n",
       "4    -0.007407  -0.257943           -0.845596                  -0.122967  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled = df.copy()\n",
    "\n",
    "columns = ['Rotational speed [rpm]', 'Torque [Nm]', 'Power [W]', 'Overstrain [minNm]', 'Heat dissipation [rpminK]']\n",
    "scaler = RobustScaler()\n",
    "features_scaled = scaler.fit_transform(df[columns])\n",
    "features_scaled = pd.DataFrame(features_scaled, columns=columns)\n",
    "df_scaled.drop(columns, axis=1, inplace=True)\n",
    "df_scaled = pd.concat([df,features_scaled], axis=1)\n",
    "\n",
    "df_scaled.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Air temperature, Process temperature and tool wear get scaled over MinMaxScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Air temperature [K]', 'Process temperature [K]', 'Tool wear [min]']\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(df[columns])\n",
    "features_scaled = pd.DataFrame(features_scaled, columns=columns)\n",
    "df_scaled.drop(columns, axis=1, inplace=True)\n",
    "df_scaled = pd.concat([df_scaled, features_scaled], axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important that the values for training data and test data are well divided, as there is a small number of errors, especially in the existing data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Target', 'Failure Type'], axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# Reset the indices\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.25, random_state=42)\n",
    "\n",
    "for train_index, test_index in cv.split(X, y):\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n",
    "print('Checking the stratified split...')\n",
    "print('Target proportion in original dataset:')\n",
    "print(df['Target'].value_counts(normalize=True))\n",
    "\n",
    "print('Target proportion in y_train dataset:')\n",
    "print(y_train.value_counts(normalize=True))\n",
    "\n",
    "print('Target proportion in y_test dataset:')\n",
    "print(y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y_Train and Y_Test have an equally good distribution and a small difference in the target values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training and Testing\n",
    "\n",
    "Specifically, we aim to classify whether a machine is functioning correctly or if it is experiencing a fault. This initial step of binary classification - distinguishing between \"faulty\" and \"operational\" states - serves several crucial purposes:\n",
    "\n",
    "- Simplicity and Clarity\n",
    "- Early Fault Detection\n",
    "- Resource Allocation\n",
    "\n",
    "Given our binary classification problem, we want to test a variety of machine learning models to determine which one performs best on our dataset. The models we plan to test include:\n",
    "\n",
    "- Logistic Regression: A simple yet effective linear model for binary classification.\n",
    "- Decision Tree Classifier: Easy to interpret and visualize, capturing non-linear relationships.\n",
    "- Random Forest Classifier: An ensemble method that builds multiple decision trees to improve accuracy and reduce overfitting.\n",
    "- Balanced Random Forest Classifier:\n",
    "- Gradient Boosting Classifier: Sequentially builds trees, each one correcting the errors of the previous one. We will also test variants like XGBoost, LightGBM, and CatBoost.\n",
    "- Bagging Classifier:\n",
    "- Balanced Bagging Classifier:\n",
    "- Easy Ensemble Classifier:\n",
    "- Support Vector Machine:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Logistic Regression\n",
      "Fitting Random Forest\n",
      "Fitting Bagging Classifier\n",
      "Fitting Balanced Random Forest\n",
      "Fitting Balanced Bagging\n",
      "Fitting Easy Ensemble\n",
      "Fitting SVC\n",
      "Fitting Gradient Boosting\n",
      "Fitting Decision Tree Classifier\n",
      "                              f1  precision  recall  roc_auc\n",
      "Random Forest             0.9344     0.9640  0.9086   0.9860\n",
      "Bagging Classifier        0.9341     0.9714  0.9029   0.9522\n",
      "Gradient Boosting         0.9307     0.9590  0.9061   0.9910\n",
      "Decision Tree Classifier  0.9072     0.9047  0.9100   0.9100\n",
      "Balanced Bagging          0.7426     0.6781  0.9317   0.9792\n",
      "Easy Ensemble             0.7246     0.6624  0.9396   0.9847\n",
      "Balanced Random Forest    0.6899     0.6362  0.9433   0.9882\n",
      "Logistic Regression       0.6559     0.8112  0.6111   0.9174\n",
      "SVC                       0.5081     0.8836  0.5084   0.9302\n",
      "Confusion Matrix for Random Forest:\n",
      "[[2407    4]\n",
      " [  15   68]]\n",
      "\n",
      "Confusion Matrix for Bagging Classifier:\n",
      "[[2406    5]\n",
      " [  18   65]]\n",
      "\n",
      "Confusion Matrix for Gradient Boosting:\n",
      "[[2401   10]\n",
      " [  16   67]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    'Bagging Classifier': BaggingClassifier(random_state=42),\n",
    "    'Balanced Random Forest': BalancedRandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    'Balanced Bagging': BalancedBaggingClassifier(random_state=42, n_jobs=-1),\n",
    "    'Easy Ensemble': EasyEnsembleClassifier(random_state=42),\n",
    "    'SVC': SVC(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'Decision Tree Classifier': DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'Fitting {name}')\n",
    "    \n",
    "    # Cross validation metrics test data\n",
    "    scoring = [\"f1_macro\", \"precision_macro\", \"recall_macro\", \"roc_auc\"]\n",
    "    cross_val_scores = cross_validate(model, X, y, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    f1_test_cv = round(cross_val_scores[\"test_f1_macro\"].mean(), 4)\n",
    "    precision_test_cv = round(cross_val_scores[\"test_precision_macro\"].mean(), 4)\n",
    "    recall_test_cv = round(cross_val_scores[\"test_recall_macro\"].mean(), 4)\n",
    "    roc_auc_test_cv = round(cross_val_scores[\"test_roc_auc\"].mean(), 4)\n",
    "    \n",
    "    # Summary table\n",
    "    score_df = pd.DataFrame({\n",
    "                     'f1': f1_test_cv,\n",
    "                     'precision': precision_test_cv,\n",
    "                     'recall': recall_test_cv,\n",
    "                     'roc_auc': roc_auc_test_cv},\n",
    "                     index=[name])\n",
    "\n",
    "    results_df = pd.concat([results_df, score_df])\n",
    "\n",
    "results_df = results_df.sort_values(by='f1', ascending=False)\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Get the names of the top 3 classifiers\n",
    "top_3_classifiers = results_df.head(3).index\n",
    "\n",
    "# Train and display confusion matrices for the top 3 classifiers\n",
    "for name in top_3_classifiers:\n",
    "    model = models[name]\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    print(f'Confusion Matrix for {name}:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top three classifiers based on F1 score are:\n",
    "\n",
    "1. Bagging Classifier: F1 score of 0.8626 with a confusion matrix showing high precision and recall.\n",
    "2. Random Forest: F1 score of 0.8449, slightly lower than Bagging, but with excellent precision and roc_auc.\n",
    "3. Decision Tree Classifier: F1 score of 0.8437, closely following Random Forest, with balanced precision and recall.\n",
    "4. Gradient Boosting: F1 score of 0.8405, slightly lower than Decision Tree, but with high precision and roc_auc.\n",
    "\n",
    "These models demonstrate strong performance, particularly in precision and roc_auc, indicating effective classification capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary on Sampling and Hyperparameter Optimization\n",
    "\n",
    "In machine learning, especially when dealing with imbalanced datasets, it is crucial to apply sampling techniques to ensure that models are trained effectively. Alongside sampling, hyperparameter optimization is essential to fine-tune model performance and achieve the best results.\n",
    "\n",
    "Sampling involves adjusting the dataset to balance the class distribution. This can be done through:\n",
    "\n",
    "- Oversampling: Increasing the number of instances in the minority class.\n",
    "- Undersampling: Reducing the number of instances in the majority class.\n",
    "\n",
    "Hyperparameter Optimization involves searching for the optimal set of parameters for a machine learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting:  RandomForestClassifier(criterion='entropy', random_state=42)\n",
      "Fitting:  BaggingClassifier(n_jobs=-1, random_state=42)\n",
      "Fitting:  DecisionTreeClassifier(random_state=42)\n",
      "Fitting:  GradientBoostingClassifier(random_state=42)\n",
      "                        model      f1     auc    sampling_method  \\\n",
      "0      RandomForestClassifier  0.9338  0.9086         TomekLinks   \n",
      "0           BaggingClassifier  0.9244  0.9022         TomekLinks   \n",
      "0  GradientBoostingClassifier  0.9188  0.9017         TomekLinks   \n",
      "0      RandomForestClassifier  0.9069  0.8951  RandomOverSampler   \n",
      "0      RandomForestClassifier  0.9051  0.9121    BorderlineSMOTE   \n",
      "0  GradientBoostingClassifier  0.9020  0.8833  RandomOverSampler   \n",
      "0      DecisionTreeClassifier  0.8941  0.8826         TomekLinks   \n",
      "0           BaggingClassifier  0.8941  0.8941  RandomOverSampler   \n",
      "0  GradientBoostingClassifier  0.8904  0.9109         SMOTETomek   \n",
      "0  GradientBoostingClassifier  0.8891  0.8937    BorderlineSMOTE   \n",
      "0           BaggingClassifier  0.8869  0.9049              SMOTE   \n",
      "0  GradientBoostingClassifier  0.8858  0.9105              SMOTE   \n",
      "0      RandomForestClassifier  0.8815  0.9215         SMOTETomek   \n",
      "0           BaggingClassifier  0.8806  0.8872    BorderlineSMOTE   \n",
      "0      DecisionTreeClassifier  0.8806  0.8872  RandomOverSampler   \n",
      "0      RandomForestClassifier  0.8759  0.9153              SMOTE   \n",
      "0           BaggingClassifier  0.8688  0.9032         SMOTETomek   \n",
      "0      DecisionTreeClassifier  0.8488  0.8955         SMOTETomek   \n",
      "0  GradientBoostingClassifier  0.8433  0.8893           NearMiss   \n",
      "0      DecisionTreeClassifier  0.8413  0.8552    BorderlineSMOTE   \n",
      "0      DecisionTreeClassifier  0.8380  0.8775              SMOTE   \n",
      "0      RandomForestClassifier  0.8259  0.9155           NearMiss   \n",
      "0           BaggingClassifier  0.8082  0.9076           NearMiss   \n",
      "0      DecisionTreeClassifier  0.7830  0.8928           NearMiss   \n",
      "0      RandomForestClassifier  0.3627  0.7167   ClusterCentroids   \n",
      "0  GradientBoostingClassifier  0.3446  0.7009   ClusterCentroids   \n",
      "0           BaggingClassifier  0.3337  0.6970   ClusterCentroids   \n",
      "0      DecisionTreeClassifier  0.3247  0.6785   ClusterCentroids   \n",
      "\n",
      "   n_estimators  min_samples_split  max_depth  min_samples_leaf  learning_rate  \n",
      "0          60.0                5.0       30.0               NaN            NaN  \n",
      "0         120.0                NaN        NaN               NaN            NaN  \n",
      "0         230.0                5.0        5.0               NaN            0.1  \n",
      "0          20.0                5.0       40.0               NaN            NaN  \n",
      "0          60.0                2.0       40.0               NaN            NaN  \n",
      "0         140.0               10.0        9.0               NaN            1.0  \n",
      "0           NaN                5.0       36.0               4.0            NaN  \n",
      "0          10.0                NaN        NaN               NaN            NaN  \n",
      "0         150.0               10.0        7.0               NaN            1.0  \n",
      "0         140.0               10.0        9.0               NaN            1.0  \n",
      "0          20.0                NaN        NaN               NaN            NaN  \n",
      "0         150.0               10.0        7.0               NaN            1.0  \n",
      "0          60.0                2.0       40.0               NaN            NaN  \n",
      "0         120.0                NaN        NaN               NaN            NaN  \n",
      "0           NaN                5.0       21.0               2.0            NaN  \n",
      "0         170.0                2.0       90.0               NaN            NaN  \n",
      "0          20.0                NaN        NaN               NaN            NaN  \n",
      "0           NaN                5.0       31.0               1.0            NaN  \n",
      "0          10.0                2.0        5.0               NaN            0.1  \n",
      "0           NaN                5.0       11.0               2.0            NaN  \n",
      "0           NaN                5.0       31.0               1.0            NaN  \n",
      "0          10.0                2.0       30.0               NaN            NaN  \n",
      "0         100.0                NaN        NaN               NaN            NaN  \n",
      "0           NaN                2.0       21.0               2.0            NaN  \n",
      "0          60.0                2.0       40.0               NaN            NaN  \n",
      "0         100.0               10.0        3.0               NaN            1.0  \n",
      "0          10.0                NaN        NaN               NaN            NaN  \n",
      "0           NaN                5.0       31.0               1.0            NaN  \n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# Define models\n",
    "RdFo = RandomForestClassifier(random_state=42, criterion='entropy')\n",
    "BBC = BaggingClassifier(random_state=42, n_jobs=-1)\n",
    "DTC = DecisionTreeClassifier(random_state=42)\n",
    "GBC = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Create NearestNeighbors object with n_jobs set\n",
    "nn = NearestNeighbors(n_jobs=-1)\n",
    "\n",
    "# Define sampling methods with NearestNeighbors object\n",
    "OverSamp_1 = RandomOverSampler(random_state=42)\n",
    "OverSamp_2 = SMOTE(random_state=42, k_neighbors=nn)\n",
    "OverSamp_3 = BorderlineSMOTE(random_state=42, k_neighbors=nn)\n",
    "UnderSamp_1 = ClusterCentroids(random_state=42)\n",
    "UnderSamp_2 = TomekLinks(n_jobs=-1)\n",
    "UnderSamp_3 = NearMiss(version=3, n_jobs=-1)\n",
    "Samp_7 = SMOTETomek()\n",
    "\n",
    "# Combine over- and undersampling methods into a list\n",
    "Samp_list = [OverSamp_1, OverSamp_2, OverSamp_3, UnderSamp_1, UnderSamp_2, UnderSamp_3, Samp_7]\n",
    "\n",
    "# Initialize results DataFrame\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each model and each sampling method\n",
    "for model in [RdFo, BBC, DTC, GBC]:\n",
    "    print(\"Fitting: \", model)\n",
    "    if isinstance(model, RandomForestClassifier):\n",
    "        grid_param = {\n",
    "            'n_estimators': np.arange(10, 300, 10),\n",
    "            'max_depth': np.arange(10, 100, 10),\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    elif isinstance(model, BaggingClassifier):\n",
    "        grid_param = {\n",
    "            'n_estimators': np.arange(10, 160, 10)\n",
    "        }\n",
    "    elif isinstance(model, DecisionTreeClassifier):\n",
    "        grid_param = {\n",
    "            'max_depth': np.arange(1, 50, 5),\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    elif isinstance(model, GradientBoostingClassifier):\n",
    "        grid_param = {\n",
    "            'n_estimators': np.arange(10, 300, 10),\n",
    "            'learning_rate': np.logspace(-3, 0, 4),\n",
    "            'max_depth': np.arange(1, 10, 2),\n",
    "            'min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "                      \n",
    "    for samp in Samp_list:\n",
    "        # Resample the training data\n",
    "        X_train_resampled, y_train_resampled = samp.fit_resample(X_train, y_train)\n",
    "\n",
    "        # Perform Randomized Search with cross-validation\n",
    "        random_search = RandomizedSearchCV(model, grid_param, cv=3, n_jobs=-1, scoring='f1_macro', refit='f1_macro', random_state=42)\n",
    "        random_search.fit(X_train_resampled, y_train_resampled)\n",
    "        y_pred = random_search.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        \n",
    "        # Create DataFrame for results\n",
    "        score_df = pd.DataFrame({\n",
    "            'model': [str(model).split('(')[0]],\n",
    "            'f1': [f1],\n",
    "            'auc': [auc],\n",
    "            'sampling_method': [str(samp).split('(')[0]]\n",
    "        })\n",
    "        \n",
    "        # Append best parameters\n",
    "        best_params = random_search.best_params_\n",
    "        for param in best_params:\n",
    "            score_df[param] = best_params[param]\n",
    "        \n",
    "        results_df = pd.concat([results_df, score_df])\n",
    "\n",
    "# Sort results by f1 score and display\n",
    "results_df = results_df.sort_values(by='f1', ascending=False)\n",
    "print(results_df.round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best results were achieved with various models and the sampling method TomekLinks. The top three models are:\n",
    "\n",
    "1. RandomForestClassifier with TomekLinks: f1-Score of 0.9338 and AUC of 0.9086.\n",
    "2. BaggingClassifier with TomekLinks: f1-Score of 0.9244 and AUC of 0.9022.\n",
    "3. GradientBoostingClassifier with TomekLinks: f1-Score of 0.9188 and AUC of 0.9017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
